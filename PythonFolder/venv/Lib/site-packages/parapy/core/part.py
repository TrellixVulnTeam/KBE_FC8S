#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2016-2021 ParaPy Holding B.V.
#
# This file is subject to the terms and conditions defined in
# the license agreement that you have received with this source code
#
# THIS CODE AND INFORMATION ARE PROVIDED "AS IS" WITHOUT WARRANTY OF ANY
# KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND/OR FITNESS FOR A PARTICULAR
# PURPOSE.

"""Documentation"""

import warnings
from functools import reduce, update_wrapper
from operator import attrgetter, getitem
from types import CodeType, FunctionType

from parapy.core.abstract import ParaPyObject
from parapy.core.abstractbase import AbstractBase
from parapy.core.abstractslot import AbstractSlot
from parapy.core.dependencies import child
from parapy.core.exceptions import (
    CompilationErrorNoSource, InvalidChild, NoArgsHandled, ParserError,
    ParserWarning, TooManyArgs)
from parapy.core.globs import CONFIGURATION, Undefined, derived
from parapy.core.parser import PartParser
from parapy.core.utilities import (
    SetterProperty, ensure_iterable, is_function_or_method, is_iterable,
    is_method)


class Part(AbstractSlot):
    """A Part slot behaves like an Attribute slot, except that:

        1. its return value must be a Base-derived instance, Undefined, or a
            sequence of these
        2. Each of the returned Base instances are turned into *children* that
            composes a *parent* object, viz::
           
            class MyClass(Base):
            
                @Part
                def child(self):
                    return MyClass()            
       
        >>> obj = MyBase()
        <MyBase root at ...>
        >>> obj.child
        <MyBase root.child at ...>
        >>> obj.child.parent
        <MyBase root at ...>
        >>> obj == obj.child.parent
        True

    The containing object is the parent and "owns" the Base objects. You can
    return these objects as the value of another part slot, but this will
    not change their parent. Once, a parent is set, it will remain unchanged.

    The recommended way to use this descriptor is::

        class MyClass(Base):

            @Part(<options>)
            def my_slot(self):
                \"\"\"docstring\"\"\"
                return Klass(**kwargs)
                
    The @Part syntax is very *strict*, because some code parsing and
    transformation takes place behind the screens that relies on this syntax
    and can fail if you deviate from the standard syntax. To appreciate what
    code conversion does, let's look at this example::
    
        class MyClass(Base):
        
            width = Input(1.0)
        
            @Input
            def box_width(self):
                print "box_width takes 10 minutes to evaluate"
                return self.width * 2.0

            @Part
            def box(self):
                return Box(width=self.box_width,
                           length=3.0)
                
    >>> obj = MyClass()
    <MyClass root at ...>
    >>> obj.box
    box_width takes 10 minutes to evaluate
    <Box root.box at XXXXXXXX>
    >>> obj.box.length
    3.0
    
    What happened here? In standard Python, there is not such a thing as
    lazy evaluation. The box expression ``Box(width = self.box_width,
    length = 3.0)`` is fully evaluated by Python once requested. This
    includes the expensive computation for ``box_width`` that takes 10
    minutes to evaluation. The expression to return the box instance has
    become a function of ``box_width``, i.e. ``box = f(box_width)``. We also
    known that box_width = f(width), and can infer that box = f(width).
    Moreover since ``box.length = f(box)``, we infer that ``box.length = f(
    width)``. This is highly un-desirable, because imagine we now change
    length and re-demand ``box.length``:
    
    >>> obj.width = 2.0
    >>> obj.box.length
    box_width takes 10 minutes to evaluate
    3.0
    
    Huh!? Surely, our length statement ``length = 3.0`` did not change in
    the meantime, so why are we forced to wait another 10 minutes for
    box_width to evaluate? Well, you should understand now from the
    above-mentioned dependencies why this is the case. When we changed
    width, box_width became invalidated, and thus box was invalidated. So,
    before answering to the length request, a completely new box object has
    been created.
    
    >>> obj.box
    <Box root.box at YYYYYYYY>
    
    Memory address XXXXXXX != YYYYYYYY. In the Knowledge-Based Engineering
    paradigm, we worship lazy, demand-driven evaluation. The scenario above
    does not behave as such however. Part slots therefore exposes a
    mechanism to separate child rules (like box.width and box.length) from
    the pure instantation code (Box), viz. the Part.bind_child_slot and
    Part.pass_down can be used to register child_rules to the child-owning
    Part slot. Hence, an equivalent and fully lazy counterpart of the box
    example is::
    
        class MyClass(Base):
    
        width = Input(1.0)
    
        @Input
        def box_width(self):
            print "box_width takes 10 minutes to evaluate"
            return self.width * 2.0

        @Part
        def box(self):
            return Box()
        box.bind_child_rule(width=box_width, length=3.0)
        
    >>> obj = MyClass()
    <MyClass root at ...>
    >>> obj.box
    <Box root.box at XXXXXXXX>
    >>> obj.box.length
    3.0
        
    Nice!? Well, sort of, but you can imagine that it requires quite some
    boilerplate typing to implement this lazy version and the syntax isn't
    to pretty. Therefore, ParaPy comes with a code parsing and
    transformation capability that allows you to code in a way that your
    used to, while it lazifies your code on the fly. Hence, when it
    encounters @Part expressions, these get transformed inside for you. Thus::
    
        @Part
        def box(self):
            return Box(width=self.box_width,
                       length=3.0)
    
    Becomes::
    
        @Part
        def box(self):
            return Box()
            
    You can ask a Part slot what it did by invoking its ``Part.source`` and
    ``Part.source_lazy`` properties. Like:
    
    >>> MyClass.box.source # Note that to reach the box slot, we ask the owning class for it
    @Part
    def box(self):
        return Box(width = self.box_width,
                   length = 3.0)
    >>> MyClass.box.source_lazy
    @Part
    def box(self):
        return Box()
    >>> MyClass.box.child_rules
    {'width': <function <lambda> at ...>, 'length': <function <lambda> at ...>}

    It is also possible not to provide a default, in which case you probably
    want to make it settable. When assigning the child, the child will have
    its parent slot set. The child cannot have a parent yet::

        class MyClass(Base):

            # Settable child slot, with initial value Undefined and docs
            my_slot = Part(doc="The docs.", settable=True)

    A working but unusual way::

        class MyClass(Base):

            # A child slot, with initial value or function
            my_slot = Part(lambda parent: ..., doc="The docs.", settable=True)
    """

    __slots__ = ['parse', 'parser', 'processor', 'child_rules', 'return_type']

    #: enables fast check from basetype. One of
    #: ["abstract", "input", "attribute", "part"]
    #: :type: str
    __ppmembername__ = "part"

    def getter(self, fn):
        """Extends AbstractSlot.getter with the option to parse the code"""
        if is_method(fn):
            fn = fn.__func__
        AbstractSlot.getter(self, fn)
        if self.parse:
            try:
                self.parser = PartParser(fn)
            except ParserError as e:
                # tell user we couldn't lazify slot, but don't fail
                if CONFIGURATION['fail_on_part_parser_error']:
                    raise
                else:
                    ParserWarning(fn, str(e))
            except IOError:
                if CONFIGURATION['fail_on_part_parser_error']:
                    raise CompilationErrorNoSource(self)
                else:
                    ParserWarning(fn, "source code unavailable")
            else:
                self._extract_parser_results()
        else:
            self.parser = None

        return self

    def __init__(self,
                 return_type=derived,
                 doc=None,
                 # override of defaults
                 settable=False,
                 trickle_down=True,
                 in_tree=True,
                 parse=CONFIGURATION["parse_part_slots"],
                 pass_down=None, map_down=None, **kwargs):

        """Overrides :py:meth:`AbstractSlot.__init__` by introduces three new attributes:

        - ``parse``: option to lazify source code by extracting child rules. Moreover,
        - ``pass_down``: to apply 1-to-1 transfer of parent slots to child slots
        - ``map_down``: to apply N-to-1 transfer for sequences

        Overrides the defaults of two inputs:
        
        - ``in_tree``: default True (shows in the user interface tree)
        - ``trickle_down`` default True, slot available in children objects        

        Kwargs:

            - parse(bool): Controls whether the parser should try to lazify the code. Defaults True.        
            - pass_down (str): see :py:meth:`Part.pass_down`
            - map_down (str): see :py:meth:`Part.map_down`
            - **kwargs: see :py:meth:`AbstractSlot.__init__`.
        """

        self.parse = parse
        self.processor = ChildProcessor(self)
        self.child_rules = {} #OrderedDict()

        # FIXME: it's good to do more type checks on fn here. To make sure user doesn't do
        # something like my_child = Part(2)
        if isinstance(return_type, type): # not return_type is derived and
            AbstractSlot.__init__(self, derived, doc=doc, settable=settable,
                                  trickle_down=trickle_down, in_tree=in_tree, **kwargs)
            # don't try to parse this code, it's not necessary
            self.default = self.return_type = return_type
            self.parse = False
            self.getter(lambda _: return_type())
        else:
            AbstractSlot.__init__(self, return_type, doc=doc, settable=settable,
                                  trickle_down=trickle_down, in_tree=in_tree, **kwargs)
        if pass_down:
            self.pass_down = pass_down
        if map_down:
            self.map_down = map_down

    def validate_fn(self, fn):
        """Overrides :py:meth:`AbstractSlot.validate_fn`. Checks method signature, viz. either 1 or
        two 2 aruments. Typically either (self) or (self, child).
        
        Args:
            fn(FunctionType|MethodType): the callable to wrap
            
        Raises:
            Exception: if fn is not valid.
        """
        if is_function_or_method(fn):
            no_args = fn.__code__.co_argcount
            if no_args == 2:
                import inspect
                _, f, ln, mod, _, _ = inspect.stack()[5]
                warnings.warn("@Part def(self, child) is deprecated.\n"
                              "File \"{:}\", line {:}, in {:}".format(f, ln, mod))
            if no_args > 2:
                args = fn.__code__.co_varnames[:no_args]
                raise SyntaxError("Decorated slot function can only have self as an argument,"
                                  " not: " + repr(args))
        else: # simple data value, make it easier to be called.
            raise Exception("Expected fn of FunctionType|MethodType, not: " + repr(fn))

    def evaluate(self, obj):
        """overrides :py:meth:`AbstractSlot.evaluate`, because it should handle delegated
        parts and it needs to post-process Base instance to become part of an assembly, viz. to
        provide a parent object, a role, etc."""

        # TODO: logging

        # the main function can never be implicitly called (self, child). Because we don't have
        # the child instance yet, we are creating it.
        result = self.fn(obj)

        #==========================================================================================
        # if isinstance(result, DelegatedPart):
        #     # finalize it!
        #     _result = result.__finalize__(obj, self)
        #     if result.process_after_finalize:
        #         self.processor.validate(_result, obj)
        #         return self.processor.compose_child(_result, obj)
        #     else:
        #         return _result
        #==========================================================================================
        self.processor.validate(result, obj)
        self.processor.compose_child(result, obj)
        return result

    def _set_value(self, obj, value, preprocess=True, validate=True):
        value = super(Part, self)._set_value(
            obj, value, preprocess=preprocess, validate=validate)

        self.processor.validate(value, obj)
        return self.processor.compose_child(value, obj)

    #==============================================================================================
    # Lazified child rule mechanism    
    #==============================================================================================
    def bind_child_rule(self, *args, **kwargs):
        """Adds named functions to child_rules dictionary. This is used internally by the 
        parser to lazify child_rules. But it can also be used by you to avoid parsing at all.
        For, example::

            class MyBase(Base):
            
                @Part
                def my_box(self):
                    return Box(width=2,
                               length=child.width)
            
        Is completely identical to::
        
            class MyBase(Base):
            
                @Part
                def my_child(self):
                    return Box()        
                
                my_box.bind_child_rule(width = lambda self: 2,
                                       length = lambda self: child.width)"""

        if "pass_down" in kwargs or "map_down" in kwargs:
            raise ValueError("for pass_down/map_down use pass_down/map_down methods.")

        if args:
            class_ = self.return_type
            if hasattr(class_, "__initargs__"):
                if not len(args) <= len(class_.__initargs__):
                    raise TooManyArgs(class_, args)
                # convert args to correct kwargs
                for key, fn in zip(class_.__initargs__, args):
                    kwargs[key] = fn
            else:
                raise NoArgsHandled(class_, args)

        if kwargs:
            for key, fn in kwargs.items():
                if is_function_or_method(fn):
                    no_args = fn.__code__.co_argcount
                    if not no_args == 1:
                        args = fn.__code__.co_varnames[:no_args]
                        msg = "Child can only have (self) as arguments,  not: "
                        raise SyntaxError(msg + repr(args))
                    else:
                        # FIXME: ideally, basetype metaclass renames child_rules to "self.__name__.key"
                        # fn.__name__ = "Part.%s" % (key,)                        
                        self.child_rules[key] = fn
                else: # simple data value, make it easier to be called.
                    self.child_rules[key] = lambda obj: fn


    @SetterProperty
    def pass_down(self, value):
        """Method to create new child rules that implement a simple 1-on-1 mapping between
        identically named slots in parent and child. The pass_down notation is a short-hand
        alternative to the tedious form::

            @Part
            def my_child(self):
                return Class(key1=self.key1,
                             key2=self.key2,
                             ...
                             keyN=self.keyN)
        
        The ``pass_down`` version of this is::
        
            @Part
            def my_child(self):
                return Class(pass_down="key1, key2, ..., keyN")
            
        In effect, this function transforms each ``keyword`` argument into a child rule through
        :py:meth:`bind_child_rule`::
         
            self.bind_child_rule(key = lambda self: getattr(self, key))
        
        In principle pass_down statements are 1-on-1 mapping between identically named slots,
        however it is also allowed to use the 'key->key' notation to achieve a 1-on-1 mapping
        between distinctly named slots (this is to achieve consistency with map_down, where
        such notation is required). So, this would work::
        
            @Part
            def a_cylinder(self):
                return Cylinder(pass_down="length->height, radius")
        
        Usage::
        
            @Part
            def my_box(self):
                return Box(pass_down="width")
            
            @Part
            def my_box(self):
                return Box(pass_down="width, length, height")
                
            @Part
            def my_box(self):
                return Box(pass_down=["width", "length", "height"])
        
        These implicit forms have explicit counterparts::

            @Part
            def my_box(self):
                return Box()            
            my_box.pass_down="width"
            my_box.pass_down="width, length, height"
            my_box.pass_down=["width", "length", "height"]"""

        if not isinstance(self, Part):
            raise Exception("You're currently calling Part.pass_down")

        if isinstance(value, str):
            args = [value]
        else:
            if not all([isinstance(_str, str) for _str in value]):
                raise ValueError("value should be a single string or an iterable of strings."
                                 " Not: %s" % (repr(value)))
            args = value
        dict_ = {} #OrderedDict()
        for child_key, parent_key  in Part._parse_pass_down_str(*args).items():
            dict_[child_key] = Part._pass_down_factory(parent_key)
        self.bind_child_rule(**dict_)

    @SetterProperty
    def map_down(self, value):
        """Method to create new child rules that binds similarly named parent-child slots. map_down
        is only useful for sequences. In effect, this function transforms each ``keyword`` argument
        into a call to :py:meth:`bind_child_rule`::

            self.bind_child_rule(keyword = lambda self: getattr(self, keyword)[child.index]).
        
        Usage::
        
            @Part
            def my_box(self):
                return Box(quantify=N,
                           map_down="widths->width")
            
            @Part
            def my_box(self):
                return Box(quantify=N,
                           map_down="widths->width, lengths->length, heights->height")
                
            @Part
            def my_box(self):
                return Box(quantify=N,
                           map_down=["widths->width", "lengths->length", "heights->height"])

        These implicit forms have explicit counterparts::

            @Part
            def my_box(self):
                return Box(quantity=3)            
            my_box.map_down = "widths->width"
            my_box.map_down = "widths->width, lengths->length, heights->height"
            my_box.map_down = ["widths->width", "lengths->length", "heights->height"]"""

        if isinstance(value, str):
            args = [value]
        else:
            if not all([isinstance(_str, str) for _str in value]):
                raise ValueError("value should be a single string or an iterable of strings."
                                 " Not: %s" % (repr(value)))
            args = value
        dict_ = {} #OrderedDict()
        for child_key, parent_key in Part._parse_pass_down_str(*args).items():
            dict_[child_key] = Part._map_down_factory(parent_key)
        self.bind_child_rule(**dict_)

    @staticmethod
    def _parse_pass_down_str(*args):
        """*args are strings only"""
        results = {} #OrderedDict()
        for string in args:
            for _str in string.split(","):
                _str = _str.strip()
                if _str:
                    if "->" in _str:
                        parent_key, child_key = (_str.strip() for _str in _str.split("->"))
                    else:
                        parent_key = child_key = _str
                    results[child_key] = parent_key
        return results

    @staticmethod
    def _pass_down_factory(name):
        """Returns a closure that implement a pass_down rule::

            lambda parent: getattr(parent, name)"""
        f = attrgetter(name)

        def fn(parent):
            return f(parent)

        fn.__name__ = "pass_down_" + name
        return fn

    @staticmethod
    def _map_down_factory(name):
        """Returns a closure that implement a map_down rule::

            lambda parent: getattr(parent, name)[child._index]
        """
        f = attrgetter(name)

        def fn(parent):
            try:
                return reduce(getitem, ensure_iterable(child._index),
                              f(parent))
            except TypeError as e:
                aggregate = child._aggregate
                if aggregate:
                    raise TypeError("%s\nParaPy help: perhaps wrong use of `map_down`? Is %s.%s a"
                                    " valid iterable to match aggregate %s." \
                                    % (e, parent._refchain, name, aggregate))
                else:
                    raise
            except IndexError as e:
                aggregate = child._aggregate
                if aggregate:
                    size_attr = iterable_size(getattr(parent, name))
                    raise IndexError("%s\nParaPy help: perhaps wrong use of `map_down`? The size"
                                     " of iterable %s.%s (%s) doesn't match size of aggregate %s." \
                                     % (e, parent._refchain, name, size_attr, aggregate))
                else:
                    raise

        fn.__name__ = "map_down_" + name
        return fn

    def _extract_parser_results(self):
        """This is called if parsing was succesful. It replaces the self.fn with the lazified
        function form and binds all child_rules."""
        parser = self.parser
        # FIXME: update co_name of new code object
        orig_fn = self.fn
        if orig_fn.__closure__:
            # There is a closure, probably the __class__ one due to super
            # being present. Remove this closure, since the child-rules
            # are removed from this function. Also we cannot create another
            # kind of closure at this moment anyway
            new_slot_fn = parser.fn_slot
            rewritten_fn = FunctionType(new_slot_fn.__code__,
                                        orig_fn.__globals__,
                                        name=orig_fn.__name__,
                                        argdefs=orig_fn.__defaults__,
                                        closure=new_slot_fn.__closure__)
            self.fn = update_wrapper(rewritten_fn, orig_fn)

            # for the child rules we need to use the original closure of the
            # method, to make sure __class__ is in it.
            reclosured = self._get_reclosured
            child_rules = {key: reclosured(value, orig_fn)
                           for (key, value) in parser.fn_child_rules.items()}
        else:
            orig_fn.__code__ = parser.fn_slot.__code__  # we patch the code
            child_rules = parser.fn_child_rules

        self.return_type = parser.return_type
        if parser.pass_down:
            self.pass_down = parser.pass_down
        if parser.map_down:
            self.map_down = parser.map_down

        self.bind_child_rule(**child_rules)

    @property
    def source_lazy(self):
        """Prints the lazified source code. Child rules have been removed if they qualified.

        Returns:
            string
        """
        return self.parser.source_lazy

    @property
    def source_no_parser(self):
        """Prints the version of this slot that doesn't require parsing.

        Returns:
            string
        """
        return self.parser.source_no_parser

    @staticmethod
    def _get_reclosured(fn, source_fn):
        """Return a ``fn`` with the same closure as ``source_fn``."""
        # rewrite code object to include the closure
        target_fn_code = fn.__code__
        source_fn_code = source_fn.__code__
        reclosured_code = CodeType(target_fn_code.co_argcount,
                                   target_fn_code.co_kwonlyargcount,
                                   target_fn_code.co_nlocals,
                                   target_fn_code.co_stacksize,
                                   target_fn_code.co_flags,
                                   target_fn_code.co_code,
                                   target_fn_code.co_consts,
                                   target_fn_code.co_names,
                                   target_fn_code.co_varnames,
                                   target_fn_code.co_filename,
                                   target_fn_code.co_name,
                                   target_fn_code.co_firstlineno,
                                   target_fn_code.co_lnotab,
                                   source_fn_code.co_freevars,
                                   target_fn_code.co_cellvars)

        reclosured_fn = FunctionType(reclosured_code,
                                     fn.__globals__,
                                     name=fn.__name__,
                                     argdefs=fn.__defaults__,
                                     closure=source_fn.__closure__)
        reclosured_fn = update_wrapper(reclosured_fn, fn)
        return reclosured_fn


class HiddenPart(Part):
    """Shouldn't go in tree"""

    def __init__(self, return_type=derived, **kwargs):
        kwargs.pop("in_tree", None)
        Part.__init__(self, return_type=return_type, in_tree=False, **kwargs)


class HiddenPartNoParsing(Part):
    """Hidden Part and no need for parsing"""

    def __init__(self, return_type=derived, **kwargs):
        kwargs.pop("parse", None)
        kwargs.pop("in_tree", None)
        Part.__init__(self, return_type=return_type, parse=False, in_tree=False, **kwargs)


class PartNoParsing(Part):
    """Already lazy slot by definition, no parsing required"""

    def __init__(self, return_type=derived, **kwargs):
        kwargs.pop("parse", None)
        Part.__init__(self, return_type=return_type, parse=False, **kwargs)


class PrivatePart(Part):
    """Private Part, shouldn't be trickled down, shouldn't go in tree"""

    def __init__(self, return_type=derived, **kwargs):
        kwargs.pop("in_tree", False)
        kwargs.pop("trickle_down", False)
        Part.__init__(self, return_type=return_type, in_tree=False,
                      trickle_down=False, **kwargs)


class PrivatePartNoParsing(Part):
    """Private Part and no need for parsing"""

    def __init__(self, return_type=derived, **kwargs):
        kwargs.pop("parse", None)
        kwargs.pop("in_tree", False)
        kwargs.pop("trickle_down", False)
        Part.__init__(self, return_type=return_type, parse=False, in_tree=False,
                      trickle_down=False, **kwargs)


class ChildProcessor(object):
    """Class to validate and compose child objects/iterables."""
    # TODO: combine validation and composition loop for performance

    def __init__(self, slot):
        self.slot = slot

    def validate(self, obj, parent):
        """A valid child is any ``obj`` of type ParaPyObject (i.e. Base, Seqence or Position) or
        Undefined, or a nested iterable of these."""
        self._validate(obj, parent, self.slot.__name__)

    def compose_child(self, obj, parent):
        """Processes the ``obj`` to become a valid child of the ``parent``.
        - converts nested iterables into immutable child_tuple objects
        - for each instance: make_child"""
        self._compose_child(obj, parent, self.slot)
        return obj

    def _validate(self, obj, parent, role, prev=None):
        if not (isinstance(obj, ParaPyObject) or obj is Undefined):
            if hasattr(obj, '__iter__'):
                for _obj in obj:
                    self._validate(_obj, parent, role, obj)
            else:
                raise InvalidChild(self.slot, parent, obj, prev or obj)

    def _compose_child(self, obj, parent, slot, indices=[], previous=None,
                       next=None):
        if isinstance(obj, AbstractBase):
            obj.make_child(parent, slot, indices, previous, next)
        elif hasattr(obj, '__iter__'):
            for index, subchild in enumerate(obj):
                self._compose_child(subchild,
                                    parent,
                                    slot,
                                    indices=indices + [index],
                                    previous=None if index == 0
                                        else obj[index - 1],
                                    next=None if index == len(obj) - 1
                                        else obj[index + 1])

#==================================================================================================
# Utility
#==================================================================================================

def iterable_size(obj):
    size = _iterable_size(obj)
    if size:
        if len(size) == 1:
            size = (1, size[0])
        return "x".join(map(str, size))
    else:
        return "0x0"

def _iterable_size(obj):
    if is_iterable(obj):
        return (len(obj),) + _iterable_size(obj[0])
    else:
        return ()
